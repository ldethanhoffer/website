<div class="columns topic">
    <div class="column">
        <h2 class="is-size-4">Machine Learning</h2>
        <div class="expand-text">
		<p>
			One would be hard-pressed to find a better place than <a href="http:/www.math.toronto.edu"> Toronto</a> to experience the current excitement around machine learning. In the past two years I have b
		</p>
		<br>
		

		<ol>
			<li class = 'li-inside-topic'> 
				<h2 class = "is-size-5"> Mathematical Foundations: </h2>
				<p> 
					Machine learning is rapidly expanding into a vast and intricate web of diverse mathematical techniques. As a result it can sometimes be tricky to maintain a clear overview of the field.<br>To contribute to this problem, I recently began the <a href = 'https://mathvsmachine.com'>math vs machine </a> project. Its goal is to construct a formal theory of machine learners and consequently explain how the major tools in use today (regression, neural networks, clustering etc.) fit inside this theory.<br>
					A nice byproduct of this project is that is was necessary to describe those techniques in the most abstract context possible, which lead to a much cleaner exposition of classical topics traditionally found in the literature.<br>
					Feel free to have a look at the accompanying <a href = 'https://www.mathvsmachine.com'> blog </a>(still under construction)  which offers a relatively informal roadmap of the project.
				</p>
				<br><br><br><br><br><br>
			</li>
			
			<hr>

			<li class = 'li-inside-topic'> 
				<h2 class = "is-size-5"> Fun Projects: </h2> 
				<p>
					In recent years, the emergence of miraculous frameworks such as <a href = 'https://www.tensorflow.org'> Tensorflow </a> or <a href = 'https://keras.io'> Keras </a>  allows us  to build sophisticated neural nets very intuitively. If you're reasonably trained in Python as well, applying your coding skills to create tools in order to solve some fun real-world problems becomes a  <br> 
					In my spare time, I like to take on projects and build some such algorithms.  To name the two most recent ones: I recently  <a href = "https://github.com/ldethanhoffer/banknote_forgery">fit</a> a neural net that detects whether a banknote is forged with 97% accuracy (as the graduating project of the Udacity <a href = 'https://in.udacity.com/course/machine-learning-engineer-nanodegree--nd009t'>ML engineer program </a>). Currently I'm part of team that's working on a  <a href = 'https://github.com/ldethanhoffer/toxic_youtube_comments'> project </a> that uses <a href = 'https://nlp.stanford.edu/pubs/glove.pdf'> natural language processing </a> techniques  together with a certain implementation of <a href = 'https://en.wikipedia.org/wiki/Long_short-term_memory'> recurrent neural nets</a> in order to recognize how and why youtube comments exhibit some form of toxicity. 
				</p>
				
				<br><br><br><br><br>
			
			</li>
			
			<hr>
			

			<li class = 'li-inside-topic'> 
				<h2 class = "is-size-5"> Machine Learning today and tomorrow: </h2> 
				<p>
					I am particulary excited about how machine learning is adopting beautiful mathematical concepts from very diverse fields in such very clever ways. As abstract concepts such as the  <a href = 'https://en.wikipedia.org/wiki/Wasserstein_metric'> Wasserstein metric</a>, <a href = 'https://en.wikipedia.org/wiki/Persistent_homology'> persistent homology </a> or even <a href = "https://en.wikipedia.org/wiki/Hyperbolic_geometry"> hyperbolic geometry </a>  get used in order to build new  models, it is becoming clear just how exciting the interplay between machine learning and current mathematics will become in the future. As part of the <a href = "http://www.cs.toronto.edu:40292"> ML group </a> at U of T, I am actively working towards a gaining a deeper collective understanding of those techniques which will in turn allow us to make the architectures of tomorrow more and more powerful.
				</p><
				
				<br><br><br>
			
			</li>
		
		</ol>
		
		</div>
    
    </div>

</div>

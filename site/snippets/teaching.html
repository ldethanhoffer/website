<div class="columns topic">
    <div class="column">
        <h2 class="is-size-4">Teaching</h2>
        <p class="expand-text">The enormous increase in processing power as well as the access to larger and larger datasets have led to an explosion of new mathematical techniques all encapsulated under the name machine learning. This idea is not new by any means: at its core, one finds a way to use a given dataset to create a cost function and assigns to a new point in the dataset the label that minimizes said function. In this sense, machine learning is all about finding clever ways to perform optimization. For example in many cases, the optimization is performed through the gradient descent method. In the setting of neural networks in particular, this algorithm has a beautiful interpretation also known as back-propagation. More recently there has been some interest in generative adversarial networks. These combine some beautiful aspects of mathematics such as game theory, probability, neural networks. I am in particular interested in the role the Wasserstein metric on random measures plays in these problems</p>
    </div>
</div>

<!DOCTYPE html>
<html lang="en-us">
<head>
    <title>Proving Linear Regression &middot; </title>
    <meta name="generator" content="Hugo 0.27.1" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="author" content="Math vs. Machine">
    
      <meta name="description" content="">
    
    
     <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.4.4/css/bulma.css" />
    <link rel="canonical" href="https://mathvsmachine.com/2017/05/20/proving-linear-regression/"/>
    <link rel="icon" href="https://mathvsmachine.com/favicon.ico">
    <link rel="apple-touch-icon" href="https://mathvsmachine.com/apple-touch-icon.png"/>
    <link rel="stylesheet" href="https://mathvsmachine.com/css/style.css">
    <link rel="stylesheet" href="https://mathvsmachine.com/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://mathvsmachine.com/css/monokai.css">
    <link rel="stylesheet" href="https://mathvsmachine.com/fancybox/jquery.fancybox.css">
    
    <link rel="stylesheet" href="https://mathvsmachine.com/css/theorems.css">
    
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400italic,400,600' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Source+Code+Pro' rel='stylesheet' type='text/css'>
    <meta property="og:title" content="Proving Linear Regression" />
<meta property="og:description" content="Last time, we introduced linear regression as a new class of learners which we called linear. Let&rsquo;s start with a little recap&hellip;
We considered a set of features $\mathfrak{X}$ together with labels which in turn took values in a finite-dimensional inner product space $\mathfrak{y}$. We next considered any finite-dimensional subspace $\mathfrak{H}\subset \mathfrak{y}^\mathfrak{X}$ of the vector space of functions $\mathfrak{X}\longrightarrow \mathfrak{y}$ as the possible hypotheses as well as a dataspace $\mathfrak{D}$ consisting of finite subsets of $\mathfrak{X}\times \mathfrak{y}$ which separate the hypothesis space $\mathfrak{H}$." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mathvsmachine.com/2017/05/20/proving-linear-regression/" />



<meta property="article:published_time" content="2017-05-20T11:58:06&#43;02:00"/>
<meta property="article:modified_time" content="2017-05-20T11:58:06&#43;02:00"/>






  
  







    
    
<meta itemprop="name" content="Proving Linear Regression">
<meta itemprop="description" content="Last time, we introduced linear regression as a new class of learners which we called linear. Let&rsquo;s start with a little recap&hellip;
We considered a set of features $\mathfrak{X}$ together with labels which in turn took values in a finite-dimensional inner product space $\mathfrak{y}$. We next considered any finite-dimensional subspace $\mathfrak{H}\subset \mathfrak{y}^\mathfrak{X}$ of the vector space of functions $\mathfrak{X}\longrightarrow \mathfrak{y}$ as the possible hypotheses as well as a dataspace $\mathfrak{D}$ consisting of finite subsets of $\mathfrak{X}\times \mathfrak{y}$ which separate the hypothesis space $\mathfrak{H}$.">


<meta itemprop="dateModified" content="2017-05-20T11:58:06&#43;02:00" />
<meta itemprop="wordCount" content="770">



<meta itemprop="keywords" content="linear regression,linear algebra,supervised learning," />

    <meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Proving Linear Regression"/>
<meta name="twitter:description" content="Last time, we introduced linear regression as a new class of learners which we called linear. Let&rsquo;s start with a little recap&hellip;
We considered a set of features $\mathfrak{X}$ together with labels which in turn took values in a finite-dimensional inner product space $\mathfrak{y}$. We next considered any finite-dimensional subspace $\mathfrak{H}\subset \mathfrak{y}^\mathfrak{X}$ of the vector space of functions $\mathfrak{X}\longrightarrow \mathfrak{y}$ as the possible hypotheses as well as a dataspace $\mathfrak{D}$ consisting of finite subsets of $\mathfrak{X}\times \mathfrak{y}$ which separate the hypothesis space $\mathfrak{H}$."/>

    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
</head>
<body>




	<header id="header">
  <div id="header-main" class="header-inner">
    <div class="outer">
      <a href="https://mathvsmachine.com" id="logo">
          
          <span class="site-title"></span>
      </a>
      <nav id="main-nav">
          
          
          <a class="main-nav-link" href="https://mathvsmachine.com/">Home</a>
          
          
          
          
          
          
          
          

          
          <a class="main-nav-link" href="/about/">About</a>
          

          
          
          
          
          <a class="main-nav-link" href="https://mathvsmachine.com/tags/">Tags</a>
          
          
          
          <a class="main-nav-link" href="https://mathvsmachine.com/files/book.pdf">The Book</a>
          
          
          
          <a class="main-nav-link" href="https://mathvsmachine.com/series/">Post Series</a>
          
          
      </nav>
        <nav id="sub-nav">
          <div class="profile" id="profile-nav">
            <a id="profile-anchor" href="javascript:;"><img class="avatar" src="https://mathvsmachine.com/css/images/bobble_logo-circle.png"><i class="fa fa-caret-down"></i></a>
          </div>
        </nav>
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form">
              <input type="search" name="q" class="search-form-input" placeholder="Search">
              <button type="submit" class="search-form-submit">
              </button>
              <input type="hidden" name="sitesearch" value="https://mathvsmachine.com" />
         </form>
        </div>
    </div>
  </div>
  <div id="main-nav-mobile" class="header-sub header-inner">
    <table class="menu outer">
      <tbody>
          <tr>
          
          
          <td><a class="main-nav-link" href="https://mathvsmachine.com/">Home</a></td>
          
          
          
          
          
          
          
          

          
          <td><a class="main-nav-link" href="/about/">About</a></td>
          

          
          
          
          
          <td><a class="main-nav-link" href="https://mathvsmachine.com/tags/">Tags</a></td>
          
          
          
          <td><a class="main-nav-link" href="https://mathvsmachine.com/files/book.pdf">The Book</a></td>
          
          
          
          <td><a class="main-nav-link" href="https://mathvsmachine.com/series/">Post Series</a></td>
          
          
          <td>
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form">
          <input type="search" name="q" class="search-form-input" placeholder="Search">
          <input type="hidden" name="sitesearch" value="https://mathvsmachine.com" />
          </form>
        </td>
      </tr>
      </tbody>
    </table>
  </div>
</header>

   	
   	<div class="outer">
   	
    	<aside id="profile">
  <div class="inner profile-inner">
    <div class="base-info profile-block">
      
      <img id="avatar" src="https://mathvsmachine.com/css/images/bobble_logo-circle.png">
      
      <h2 id="name">Math vs. Machine</h2>
      <h3 id="title">Louis de Thanhoffer de Volcsey</h3>
      
      
          <a id="follow" href="https://louisdethanhoffer.com">
              Website
          </a>
      
    </div>
    <div class="article-info profile-block">
      <div class="article-info-block">
        6
        <span>Posts</span>
      </div>
      <div class="article-info-block">
        
          3
        
        <span>
            Tags
        </span>
      </div>
    </div>
    <div class="profile-block social-links">
      <table>
        <tr>
          
<td><a href="//github.com/ldethanhoffer" target="_blank" title="GitHub"><i class="fa fa-github"></i></a></td>



<td><a href="//linkedin.com/in/louisdethanhoffer" target="_blank" title="LinkedIn"><i class="fa fa-linkedin"></i></a></td>




<td><a href="//quora.com/Louis-de-Thanhoffer-de-Volcsey" target="_blank" title="Quora"><i class="fa fa-quora"></i></a></td>




<td><a href="//quora.com/Louis-de-Thanhoffer-de-Volcsey" target="_blank" title="Quora"><i class="fa fa-quora"></i></a></td>

          <td><a href="https://mathvsmachine.com/index.xml" target="_blank" title="RSS"><i class="fa fa-rss"></i></a></td>
        </tr>
      </table>
    </div>
  </div>
</aside>

    

    <section id="main">
    
    <article id="page-undefined" class="article article-type-page" itemscope="" itemprop="blogPost">
    <div class="article-inner">
        
            <img src="https://mathvsmachine.com/banners/pseudo_inverse_ev.png" class="article-banner">
        

        

<header class="article-header">
    <a href="https://mathvsmachine.com/2017/05/20/proving-linear-regression/">
    <h1 class="article-title" itemprop="name">
        Proving Linear Regression
    </h1>
    </a>
    <div class="article-meta">

        
        <div class="article-date">
            <i class="fa fa-calendar"></i>
            <time datetime="2017-05-20 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2017-05-20</time>
            &middot;
            
            770
            words
            &middot;
            
            
            
        
        </div>
        
        
            
            
            <div class="article-category">
                <i class="fa fa-folder"></i>
                
                
                <a class="article-category-link" href="https://mathvsmachine.com/series/linear-regression">linear regression</a>
                
                
            </div>
            
        
        
        
            
            
            <div class="article-category">
                <i class="fa fa-list-alt"></i>
                
                
                <a class="article-category-link" href="https://mathvsmachine.com/series/linear-regression">linear regression</a>
                
                
            </div>
            
        

    </div>
</header>

        <div class="article-entry" itemprop="articleBody">
            <p><a href="https://mathvsmachine.com/2017/05/20/introducing-linear-regression..a-little-differently/">Last time</a>, we introduced linear regression as a new class of <a href="https://mathvsmachine.com/2017/05/20/defining-supervised-learning/">learners</a> which we called linear. Let&rsquo;s start with a little recap&hellip;</p>

<p>We considered a set of features $\mathfrak{X}$ together with labels which in turn took values in a finite-dimensional inner product space $\mathfrak{y}$.  We next considered any finite-dimensional subspace $\mathfrak{H}\subset \mathfrak{y}^\mathfrak{X}$ of the vector space of functions $\mathfrak{X}\longrightarrow \mathfrak{y}$ as the possible hypotheses as well as a dataspace $\mathfrak{D}$ consisting of finite subsets of $\mathfrak{X}\times \mathfrak{y}$ which <a href="https://mathvsmachine.com/2017/05/20/introducing-linear-regression..a-little-differently/">separate</a> the hypothesis space $\mathfrak{H}$. We finally associated to any dataset $\Delta \in \mathfrak{D}$ and any hypothesis $f \in \mathfrak{H}$ a cost which was simply the norm of the vector $\big(f(x)-y)\big)_{(x,y) \in \Delta}$ in the space $\mathfrak{y}^\Delta$ or more explicitely:
 $$c(\Delta, f) = \vert \vert (f(x)-y)_{(x,y)\in \Delta}\vert \vert_{\mathfrak{y}^\Delta} =  \sum_{(x,y) \in \Delta}\sqrt{\vert \vert f(x)-y\vert \vert^2_\mathfrak{y}}$$
We then claimed (without proof )that this indeed defines a <a href="https://mathvsmachine.com/2017/05/20/defining-supervised-learning/">sharp learner</a> in the sense that for any dataset $\Delta \in \mathfrak{D}$, the learned hypothesis which by definition is given by $$h_\Delta := \textrm{argmin}_{f\ \in \mathfrak{H}} c(\Delta,f) $$
was indeed well defined</p>

<p>The proof is actually rather easy, and today we will guide you through the steps:</p>

<p>Let&rsquo;s begin by recalling the following fact from linear algebra:</p>

<div class = "lemma" >
Let $W\subset V$ be a subspace of a finite dimensional inner product space $V$. Then the following are equivalent:
<ol>
<li> the vector $ v-w$ is orthogonal to the subspace $ W$</li>
<li>$\vert \vert v-w\vert \vert \le \vert \vert v-u\vert \vert $  $, \forall u \in W$ </li>
</ol> 
Moreover, the vector $w$ satisfying either condition is necessarily unique
</div>

<p>The above lemma tells us that the <em>projection</em> onto the subspace $W$ defined as $\pi(v)=\text{argmin}_{w \in W}\vert \vert v-w\vert \vert$ coincides with the other notion of <em>projection</em> of onto the subspace $W$ by considering the decomposition of $V$ into $V=W\oplus W^{\perp}$ and writing $v = w+(v-w)$. We will call $w$ map <em>the</em> projection of $v$ onto $W$ as no confusion can arise.</p>

<p>In fact we&rsquo;ll be interested in a slight variation of the above definition: instead of a subspace, we&rsquo;ll consider a  linear map $f:V\longrightarrow W$ and assume that $W$ is now a finite dimensional inner product space. We let $U$ denote the subspace $U=\text{im}(f)\subset W$. Now, for any vector $w \in W$ we can ask what the projection of $w$ onto $U$ looks like. There is a very nice answer to this question:</p>

<div class = "lemma">
The following are equivalent:
<ol>
    <li>$f(v)$ is the projection of $w$ onto $U$</li>
    <li>the vector $v \in V$ satisfies $(f^* \circ f)(v) = f^*(w)$ </li>
</ol>
The above equation is called the normal equation.
</div>
An important remark is that if the map $f$ is injective, this vector $v$ is necessarily unique! (since we know that $f(v)$ is unique by the previous lemma, and $f(v)$ can have only one pre-image by injectivity in this case). In this case we'll use the following notation to denote $v$:
$$
v= f^+(w)
$$
<center>
It turns out that this above lemma is exactly what we need to prove the promised claim of linear regression being indeed a sharp learner.<br><br>
</center>
 Here's how to do it:  
Assume the dataset $\Delta \in \mathfrak{D}$ is given.. Then $\Delta$ consists of a finite set of couples $(x,y)\in \mathfrak{X}\times \mathfrak{y}$ and separates $\mathfrak{H}$, in the sense that if $f$ and $g$ coincide on $\Delta$, then $f=g$.  

Now consider the map:  

<center>
$$\textrm{ev}_\Delta: \mathfrak{H}\longrightarrow \mathfrak{y}^\Delta: f \longrightarrow (f(x))_{x\in \Delta}$$
</center>  

Note that \( \mathfrak{y}^\Delta \) being a finite product of finite-dimensional inner product spaces is itself an inner product space!
Now, $\text{ev}_\Delta$ is clearly a linear map, so we let $U=\text{im}(\text{ev}_\Delta)$ denote the image subspace in $\mathfrak{y}^\Delta$. Now the separation condition of $\Delta$ translates exactly into the fact that $\text{ev}_\Delta$ is injective. We can thus apply the previous lemma to write:
$$h_\Delta = \text{ev}^+_\Delta\big((y)_{(x,y) \in \Delta}\big)$$

In other words, $h_\Delta$ is the unique hypothesis in $\mathfrak{H}$ such that $\textrm{ev}_\Delta (h_\Delta)$ is the projection of the labels $\big((y)_{(x,y)\in \Delta}\big)$ of the dataset onto the image of $\text{ev}_\Delta$ (it's a mouthful, I agree).  
The first lemma now implies that this in turn is equivalent to 
$$ h_\Delta =\text{argmin}_{f\in U}\vert \vert \text{ev}_\Delta(f)-(y)_{(x,y) \in \Delta} \vert \vert_{\mathfrak{y}^\Delta}$$ 
But that in turn is equivalent to 
$$= \text{argmin}_{f\in U}\vert \vert \big(f(x)_{(x,y)\in \Delta}\big)-\big((y)_{(x,y) \in \Delta}\big) \vert \vert_{\mathfrak{y}^\Delta}=\vert \vert (f(x)-y)_{(x,y)\in \Delta}\vert \vert_{\mathfrak{y}^\Delta}$$ 
Which is exactly what we wanted!  

We can summarize:

<div class ="theorem">
The setup $\bigg(\mathfrak{X},\mathfrak{y},\mathfrak{H},\mathfrak{D},c\bigg)$ where $\mathfrak{X}$ is any set, $\mathfrak{y}$ a finite-dimensional inner product space $\mathfrak{H}\subset \mathfrak{y}^\mathfrak{X}$ a finite-dimensional subspace, $\mathfrak{D}$ consists of finite subsets of $\mathfrak{X}\times \mathfrak{y}$ that separate $\mathfrak{H}$ and $c(\Delta, f) = \vert \vert \big(f(x)-y\big)_{(x,y\in \Delta}\vert \vert_{\mathfrak{y}^\Delta}$ defines a sharp learner.  
The learned hypothesis is given as
$$
h_\Delta = \text{ev}_\Delta^+\big((y)_{(x,y) \in \Delta}\big)
$$
where
$$
\text{ev}_\Delta: \mathfrak{H}\longrightarrow \mathfrak{y}^\Delta: f \mapsto (f(x))_{x\in \Delta}$$

</div>

        </div>
        <footer class="article-footer">
    <a data-url="https://mathvsmachine.com/2017/05/20/proving-linear-regression/" data-id="e9ea2743e59ebdacb2e839f0074380ed" class="article-share-link">
        <i class="fa fa-share"></i>
        Share
    </a>
    
    <a href="https://mathvsmachine.com/2017/05/20/proving-linear-regression/#disqus_thread" class="article-comment-link">
        Comments
    </a>
    

    <script>
    (function ($) {
        
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
    </script>
</footer>

    </div>

    
<nav id="article-nav">
    
    <a href="https://mathvsmachine.com/2017/05/20/roundup/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">
          Older
      </strong>
      <div class="article-nav-title">Roundup</div>
    </a>
    

    
    <a href="https://mathvsmachine.com/2017/05/20/introducing-linear-regression..a-little-differently/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">
          Newer
      </strong>
      <div class="article-nav-title">Introducing linear regression..a little differently</div>
    </a>
    
</nav>


</article>


<section id="comments">
    <div id="disqus_thread">
        <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "louis-de-thanhoffer" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
</section>


    </section>

   	
    	<aside id="sidebar">
    



<div class="widget-wrap">
    <h3 class="widget-title">
        Recents
    </h3>
    <div class="widget">
        <ul id="recent-post">
            
            <li>
                <div class="item-thumbnail">
                    <a href="https://mathvsmachine.com/2017/05/20/coordinates-regression-the-way-we-know-it/" class="thumbnail">
                    
                        <span style="background-image:url(https://mathvsmachine.com/thumbnails/linear_regression.png)" alt="Proving Linear Regression" class="thumbnail-image"></span>
                    
                    </a>
                </div>
                <div class="item-inner">
                    
                    
                    <p class="item-title"><a href="https://mathvsmachine.com/2017/05/20/coordinates-regression-the-way-we-know-it/" class="title">Coordinates: Regression the way we know it</a></p>
                    <p class="item-date">
                        <time datetime="2017-05-20 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2017-05-20</time>
                    </p>
                </div>
            </li>
            
            <li>
                <div class="item-thumbnail">
                    <a href="https://mathvsmachine.com/2017/05/20/defining-supervised-learning/" class="thumbnail">
                    
                        <span style="background-image:url(https://mathvsmachine.com/thumbnails/supervised_learning.png)" alt="Proving Linear Regression" class="thumbnail-image"></span>
                    
                    </a>
                </div>
                <div class="item-inner">
                    
                    
                    <p class="item-title"><a href="https://mathvsmachine.com/2017/05/20/defining-supervised-learning/" class="title">Defining Supervised Learning</a></p>
                    <p class="item-date">
                        <time datetime="2017-05-20 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2017-05-20</time>
                    </p>
                </div>
            </li>
            
            <li>
                <div class="item-thumbnail">
                    <a href="https://mathvsmachine.com/2017/05/20/disecting-pseudo-inverses/" class="thumbnail">
                    
                        <span style="background-image:url(https://mathvsmachine.com/thumbnails/linear_regression.png)" alt="Proving Linear Regression" class="thumbnail-image"></span>
                    
                    </a>
                </div>
                <div class="item-inner">
                    
                    
                    <p class="item-title"><a href="https://mathvsmachine.com/2017/05/20/disecting-pseudo-inverses/" class="title">Disecting Pseudo-inverses</a></p>
                    <p class="item-date">
                        <time datetime="2017-05-20 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2017-05-20</time>
                    </p>
                </div>
            </li>
            
            <li>
                <div class="item-thumbnail">
                    <a href="https://mathvsmachine.com/2017/05/20/introducing-linear-regression..a-little-differently/" class="thumbnail">
                    
                        <span style="background-image:url(https://mathvsmachine.com/thumbnails/linear_regression.png)" alt="Proving Linear Regression" class="thumbnail-image"></span>
                    
                    </a>
                </div>
                <div class="item-inner">
                    
                    
                    <p class="item-title"><a href="https://mathvsmachine.com/2017/05/20/introducing-linear-regression..a-little-differently/" class="title">Introducing linear regression..a little differently</a></p>
                    <p class="item-date">
                        <time datetime="2017-05-20 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2017-05-20</time>
                    </p>
                </div>
            </li>
            
            <li>
                <div class="item-thumbnail">
                    <a href="https://mathvsmachine.com/2017/05/20/proving-linear-regression/" class="thumbnail">
                    
                        <span style="background-image:url(https://mathvsmachine.com/thumbnails/linear_algebra.png)" alt="Proving Linear Regression" class="thumbnail-image"></span>
                    
                    </a>
                </div>
                <div class="item-inner">
                    
                    
                    <p class="item-title"><a href="https://mathvsmachine.com/2017/05/20/proving-linear-regression/" class="title">Proving Linear Regression</a></p>
                    <p class="item-date">
                        <time datetime="2017-05-20 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2017-05-20</time>
                    </p>
                </div>
            </li>
            
        </ul>
    </div>
</div>


    



    



    





<div class="widget-wrap">
    <h3 class="widget-title">
        Tag cloud
    </h3>
    <div class="widget tagcloud">
        
        
        <a href="https://mathvsmachine.com/tags/linear-algebra" style="font-size: 12px;">linear-algebra</a>
        
        
        <a href="https://mathvsmachine.com/tags/linear-regression" style="font-size: 12px;">linear-regression</a>
        
        
        <a href="https://mathvsmachine.com/tags/supervised-learning" style="font-size: 12px;">supervised-learning</a>
        
    </div>
</div>




    




<div class="widget-wrap">
    <h3 class="widget-title"></h3>
    <div class="widget">
        <ul class="category-list">
            
            <li class="category-list-item">
                
                <a class="category-list-link" href="https://mathvsmachine.com/series/linear-regression">
                    linear-regression
                </a>
                <span class="category-list-count">5</span>
            </li>
            
            <li class="category-list-item">
                
                <a class="category-list-link" href="https://mathvsmachine.com/series/supervised-learning">
                    supervised-learning
                </a>
                <span class="category-list-count">1</span>
            </li>
            
        </ul>
    </div>
</div>





    <div id="toTop" class="fa fa-angle-up"></div>
</aside>

    
	


<footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019
      Powered by <a href="//gohugo.io">Hugo</a>.
    </div>
  </div>
</footer>


<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-120720172-1', 'auto');
ga('send', 'pageview');
</script>

<script src="https://mathvsmachine.com/fancybox/jquery.fancybox.pack.js"></script>
<script src="https://mathvsmachine.com/js/script.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>


<script src="https://sonoisa.github.io/xyjax_ext/xypic.js"></script>

<script>hljs.initHighlightingOnLoad();</script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>




</body>
</html>
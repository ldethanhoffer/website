<!DOCTYPE html>
<html lang="en-us">
<head>
    <title>Introducing linear regression..a little differently &middot; </title>
    <meta name="generator" content="Hugo 0.27.1" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="author" content="Math vs. Machine">
    
      <meta name="description" content="">
    
    
     <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.4.4/css/bulma.css" />
    <link rel="canonical" href="https://mathvsmachine.com/2018/11/20/introducing-linear-regression..a-little-differently/"/>
    <link rel="icon" href="https://mathvsmachine.com/favicon.ico">
    <link rel="apple-touch-icon" href="https://mathvsmachine.com/apple-touch-icon.png"/>
    <link rel="stylesheet" href="https://mathvsmachine.com/css/style.css">
    <link rel="stylesheet" href="https://mathvsmachine.com/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://mathvsmachine.com/css/monokai.css">
    <link rel="stylesheet" href="https://mathvsmachine.com/fancybox/jquery.fancybox.css">
    
    <link rel="stylesheet" href="https://mathvsmachine.com/css/theorems.css">
    
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400italic,400,600' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Source+Code+Pro' rel='stylesheet' type='text/css'>
    <meta property="og:title" content="Introducing linear regression..a little differently" />
<meta property="og:description" content="Anyone who&rsquo;s taken an intro to statistics class is familiar with the basic concept of linear regression&hellip;
The quintessential example is guessing house prices: let&rsquo;s say you go around houses in your neighborhood collecting some data on each house (the square footage, the number of bedrooms, the size of the yard and the age of the house for example). You also ask your neighbors the selling price for each house. The idea is to estimate the selling price of your own house based off the info you gathered&hellip;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mathvsmachine.com/2018/11/20/introducing-linear-regression..a-little-differently/" />



<meta property="article:published_time" content="2018-11-20T11:58:06&#43;02:00"/>
<meta property="article:modified_time" content="2018-11-20T11:58:06&#43;02:00"/>






  
  







    
    
<meta itemprop="name" content="Introducing linear regression..a little differently">
<meta itemprop="description" content="Anyone who&rsquo;s taken an intro to statistics class is familiar with the basic concept of linear regression&hellip;
The quintessential example is guessing house prices: let&rsquo;s say you go around houses in your neighborhood collecting some data on each house (the square footage, the number of bedrooms, the size of the yard and the age of the house for example). You also ask your neighbors the selling price for each house. The idea is to estimate the selling price of your own house based off the info you gathered&hellip;">


<meta itemprop="dateModified" content="2018-11-20T11:58:06&#43;02:00" />
<meta itemprop="wordCount" content="1177">



<meta itemprop="keywords" content="linear regression,supervised learning," />

    <meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Introducing linear regression..a little differently"/>
<meta name="twitter:description" content="Anyone who&rsquo;s taken an intro to statistics class is familiar with the basic concept of linear regression&hellip;
The quintessential example is guessing house prices: let&rsquo;s say you go around houses in your neighborhood collecting some data on each house (the square footage, the number of bedrooms, the size of the yard and the age of the house for example). You also ask your neighbors the selling price for each house. The idea is to estimate the selling price of your own house based off the info you gathered&hellip;"/>

    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
</head>
<body>




	<header id="header">
  <div id="header-main" class="header-inner">
    <div class="outer">
      <a href="https://mathvsmachine.com" id="logo">
          
          <span class="site-title"></span>
      </a>
      <nav id="main-nav">
          
          
          <a class="main-nav-link" href="https://mathvsmachine.com/">Home</a>
          
          
          
          
          
          
          
          

          
          <a class="main-nav-link" href="/about/">About</a>
          

          
          
          
          
          <a class="main-nav-link" href="https://mathvsmachine.com/tags/">Tags</a>
          
          
          
          <a class="main-nav-link" href="https://github.com/ldethanhoffer/MathvsMachine-the-book/blob/master/book.pdf">The Book</a>
          
          
          
          <a class="main-nav-link" href="https://mathvsmachine.com/series/">Post Series</a>
          
          
      </nav>
        <nav id="sub-nav">
          <div class="profile" id="profile-nav">
            <a id="profile-anchor" href="javascript:;"><img class="avatar" src="https://mathvsmachine.com/css/images/bobble_logo-circle.png"><i class="fa fa-caret-down"></i></a>
          </div>
        </nav>
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form">
              <input type="search" name="q" class="search-form-input" placeholder="Search">
              <button type="submit" class="search-form-submit">
              </button>
              <input type="hidden" name="sitesearch" value="https://mathvsmachine.com" />
         </form>
        </div>
    </div>
  </div>
  <div id="main-nav-mobile" class="header-sub header-inner">
    <table class="menu outer">
      <tbody>
          <tr>
          
          
          <td><a class="main-nav-link" href="https://mathvsmachine.com/">Home</a></td>
          
          
          
          
          
          
          
          

          
          <td><a class="main-nav-link" href="/about/">About</a></td>
          

          
          
          
          
          <td><a class="main-nav-link" href="https://mathvsmachine.com/tags/">Tags</a></td>
          
          
          
          <td><a class="main-nav-link" href="https://github.com/ldethanhoffer/MathvsMachine-the-book/blob/master/book.pdf">The Book</a></td>
          
          
          
          <td><a class="main-nav-link" href="https://mathvsmachine.com/series/">Post Series</a></td>
          
          
          <td>
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form">
          <input type="search" name="q" class="search-form-input" placeholder="Search">
          <input type="hidden" name="sitesearch" value="https://mathvsmachine.com" />
          </form>
        </td>
      </tr>
      </tbody>
    </table>
  </div>
</header>

   	
   	<div class="outer">
   	
    	<aside id="profile">
  <div class="inner profile-inner">
    <div class="base-info profile-block">
      
      <img id="avatar" src="https://mathvsmachine.com/css/images/bobble_logo-circle.png">
      
      <h2 id="name">Math vs. Machine</h2>
      <h3 id="title">Louis de Thanhoffer de Volcsey</h3>
      
      
          <a id="follow" href="https://louisdethanhoffer.com">
              Website
          </a>
      
    </div>
    <div class="article-info profile-block">
      <div class="article-info-block">
        6
        <span>Posts</span>
      </div>
      <div class="article-info-block">
        
          3
        
        <span>
            Tags
        </span>
      </div>
    </div>
    <div class="profile-block social-links">
      <table>
        <tr>
          
<td><a href="//github.com/ldethanhoffer" target="_blank" title="GitHub"><i class="fa fa-github"></i></a></td>



<td><a href="//linkedin.com/in/louisdethanhoffer" target="_blank" title="LinkedIn"><i class="fa fa-linkedin"></i></a></td>




<td><a href="//quora.com/Louis-de-Thanhoffer-de-Volcsey" target="_blank" title="Quora"><i class="fa fa-quora"></i></a></td>




<td><a href="//quora.com/Louis-de-Thanhoffer-de-Volcsey" target="_blank" title="Quora"><i class="fa fa-quora"></i></a></td>

          <td><a href="https://mathvsmachine.com/index.xml" target="_blank" title="RSS"><i class="fa fa-rss"></i></a></td>
        </tr>
      </table>
    </div>
  </div>
</aside>

    

    <section id="main">
    
    <article id="page-undefined" class="article article-type-page" itemscope="" itemprop="blogPost">
    <div class="article-inner">
        
            <img src="https://mathvsmachine.com/banners/linear_learner_cost.png" class="article-banner">
        

        

<header class="article-header">
    <a href="https://mathvsmachine.com/2018/11/20/introducing-linear-regression..a-little-differently/">
    <h1 class="article-title" itemprop="name">
        Introducing linear regression..a little differently
    </h1>
    </a>
    <div class="article-meta">

        
        <div class="article-date">
            <i class="fa fa-calendar"></i>
            <time datetime="2018-11-20 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2018-11-20</time>
            &middot;
            
            1177
            words
            &middot;
            
            
            
        
        </div>
        
        
            
            
            <div class="article-category">
                <i class="fa fa-folder"></i>
                
                
                <a class="article-category-link" href="https://mathvsmachine.com/series/linear-regression">linear regression</a>
                
                
            </div>
            
        
        
        
            
            
            <div class="article-category">
                <i class="fa fa-list-alt"></i>
                
                
                <a class="article-category-link" href="https://mathvsmachine.com/series/linear-regression">linear regression</a>
                
                
            </div>
            
        

    </div>
</header>

        <div class="article-entry" itemprop="articleBody">
            <p>Anyone who&rsquo;s taken an intro to statistics class is familiar with the basic concept of linear regression&hellip;</p>

<p>The quintessential example is guessing house prices: let&rsquo;s say you go around houses in your neighborhood collecting some data on each house (the square footage, the number of bedrooms, the size of the yard and the age of the house for example). You also ask your neighbors the selling price for each house. The idea is to estimate the selling price of your own house based off the info you gathered&hellip;</p>

<p>How?</p>

<p>Well, the data of each house essentially forms a point in the vector space $\mathbb{R}^4$. The price of the house in turn is a value in the vector space $\mathbb{R}$. The technique of linear regression now produces a linear map $h: \mathbb{R}^4\longrightarrow \mathbb{R}$ that <em>&lsquo;best describes the data&rsquo;</em>. Your own selling price should now be the value of $h$ when you plug in the paramaters of your own house.</p>

<p>In this first post on linear regression, we intend to do two things:</p>

<ol>
<li>Show you how we can take this example and generalize it <em>immensely</em></li>
<li>Describe how this generalization fits nicely in the language of <a href="https://mathvsmachine.com/2019/01/20/defining-supervised-learning/">supervised learners</a> we defined before</li>
</ol>

<p>Let&rsquo;s begin by working out our house price example in a little more detail, introducing some terminology along the way:<br />
The sample of houses will be the <em>dataset</em> $\Delta$ consisting of elements $(x,y)$ where the <em>feature</em> $x \in \mathbb{R}^4$ contains all the information of the house and the <em>label</em> $y$ is the corresponding selling price of the house. Saying that $h$ <em>fits the data $\Delta$ best</em> means that $h$ predicts the selling price  $y$ from the feature $x$ as accurately as possible. In other words, for all houses, the error in prediction $\big(h(x)-y\big)$ must be minimized according to some cost.</p>

<p>The most elegant way to do this is to view the sequence $v= \big(h(x)-y\big)_{(x,y)\in \Delta}$ as a single vector in the vector space $\mathbb{R}^{\vert \Delta \vert}$ and to consider the obvious norm on $\mathbb{R}^{\vert \Delta \vert}$. In other words, we wish to find the  function $h$ that minimizes  the value $$\vert \vert v \vert \vert = \sqrt{\sum _{(x,y)\in\Delta}\big( h(x)-y\big)^2}$$<br />
Any standard textbook in statistics will now tell you that as long as the features $x \in \Delta$ span the the vector space $\mathbb{R}^4$, there always exists a unique $h$ that minimizes $\vert \vert v\vert \vert$. They&rsquo;ll usually tell you that this $h$ corresponds to a $1\times 4$ matrix and there is something called the normal equation that provides you with the unique solution. More on that <a href="https://mathvsmachine.com/2019/02/03/coordinates-regression-the-way-we-know-it/">later</a>&hellip;</p>

<p>Now, let&rsquo;s take this example one step further: the fact that the features and labels were elements of the sets $\mathbb{R}^4$ and $\mathbb{R}$ is of course totally irrelevant. Instead, we only need two finite-dimensional vector spaces, say $V$ and $W$ respectively, which are equipped with an inner product (this so that we can talk about the hypothesis <em>best fitting the data</em> later on).<br />
In our more general linear regression, we again begin with a dataset $\Delta \subset V \times W$ consisting of points $(x,y)$ and wish to find the hypothesis $h \in \text{Hom}_{\mathbb{R}}(V,W)$ that fits $\Delta$ best. Again, let&rsquo;s look at all the errors in predictions $v= \big( h(x)-y\big)_{(x,y)\in \Delta}$ as a single vector $v$ in the vector space $W^{\vert \Delta \vert}$. It&rsquo;s well know that $W^{\vert \Delta \vert}$  carries a natural inner product space with norm</p>

<p>$$
\vert \vert v \vert \vert_{W^{\vert \Delta \vert}} = \sqrt{ \sum_{(x,y)} \vert\vert h(x)-y \vert\vert_W^2}
$$
So in this more general example, we&rsquo;ll want to find $h$ that minimizes the above quantity</p>

<p>In the <a href="https://mathvsmachine.com/2018/12/01/proving-linear-regression/">next post</a> we will outline the proof that this map $h$ exists uniquely as long as the features $x \in \Delta$ span the vector space $V$!</p>

<p>Now, the very careful reader will spot that there is one more level of generality we can consider: Indeed, the above norm really only depends on the inner product in the vector space $W$. The problem thus only requires $W$ to be an inner product space (in other words it&rsquo;s independent of the norm on $V$)</p>

<p>So -in principle- we could simply consider any dataset $\Delta \in \mathfrak{X}\times \mathfrak{y}$ where $\mathfrak{X}$ is <strong>any set</strong> , $\mathfrak{y}$ a finite-dimensional inner product space, and consider the analgous linear regression problem for this dataset.</p>

<p>One first hurdle would be to answer the question:
<center>
What does the word linear mean in this context?
</center></p>

<p>There&rsquo;s an easy way to answer this: the set of functions $\mathfrak{X}^\mathfrak{y}$ is naturally a vector space. We now pick <em>any</em> subspace $\mathfrak{H}$ of $\mathfrak{X}^\mathfrak{y}$ that is finite-dimensional.
The new linear regression context now asks to find a unique function $h \in \mathfrak{H}$ which minimizes the norm:
$$
\vert \vert v \vert \vert_{\mathfrak{y}^{\vert \Delta \vert}} = \sqrt{\sum_{(x,y)\in\Delta}\vert \vert  h(x)-y\vert \vert_{\mathfrak{y}}^2}
$$</p>

<p>In the above two examples we needed a little extra condition (the features in $\Delta$ need to span the vector space). We can easily translate this condition as follows:
<div class = 'definition'>
We say that a dataset $\Delta \subset \mathfrak{X}\times \mathfrak{y}$ separates the space $\mathfrak{H}\subset \mathfrak{X}^\mathfrak{y}$ if for any two functions $f,g \in \mathfrak{H}$, we have $$f_\Delta = g_\Delta \implies f = g$$
</div></p>

<p>The <a href="https://mathvsmachine.com/2018/12/01/proving-linear-regression/">next post</a>, we will also prove that under the condition of separation, a unique $h \in \mathfrak{H}$ indeed minimizes the above norm.</p>

<p>Summing up:
<div class = 'lemma'>
Let $\mathfrak{X}$ be any set and $\mathfrak{y}$ be any finite dimensional inner product space. Let $\mathfrak{H}\subset \mathfrak{X}^\mathfrak{y}$ be any finite dimensional subspace. Then for any finite set $\Delta \in \mathfrak{X}\times \mathfrak{y}$ that separates $\mathfrak{H}$, there exists  a unique $h_\Delta \in \mathfrak{H}$ such that</p>

<p>$$
\vert \vert h(x)-y \vert \vert_{\mathfrak{y}^\Delta} = \sqrt{\sum_{(x,y)} \vert \vert h(x)-y\vert \vert_{\mathfrak{y}}^2}
$$</p>

<p>is minimal
</div>
As promised above, we will also reformulate the above lemma in the context of our theory of <a href="https://mathvsmachine.com/2019/01/20/defining-supervised-learning/">learners</a>  .<br />
Recall that a sharp learner consists of a set of features $\mathfrak{X}$, a set of labels $\mathfrak{y}$, together with a hypothesis space given as a set $\mathfrak{H}\subset \mathfrak{y}^\mathfrak{X}$, a dataspace $\mathfrak{D}$ consisting of finite subsets of $\mathfrak{X}\times \mathfrak{y}$ and a cost function $c: \mathfrak{D}\times \mathfrak{H}\longrightarrow \mathbb{R}$ for which the function $h_\Delta = \textrm{argmin}_{f \in \mathfrak{H}}c(\Delta,f)$ is well defined..</p>

<p>We can now restate the above lemma as follows:</p>

<div class = 'theorem' >
(Linear regression)  
Let $\mathfrak{X}$ be any set and $\mathfrak{y}$ be any finite dimensional inner product space. Let $\mathfrak{H}\subset \mathfrak{X}^\mathfrak{y}$ be any finite dimensional subspace and assume $\mathfrak{D}$ consists of finite $\Delta \subset \mathfrak{X}\times \mathfrak{y}$ that separate $\mathfrak{H}$.  
Let 
$$c: \mathfrak{D}\times \mathfrak{H}:(\Delta, f) \mapsto \vert \vert h(x)-y\vert \vert_{\mathfrak{y}^\Delta}$$
Then $(\mathfrak{X}, \mathfrak{y},\mathfrak{H},\mathfrak{D},c)$ defines a sharp learner called a linear learner
</div>

<p>Of course our second example provides a specific construction of such a linear learner:</p>

<div class = 'example'>
Let $\mathfrak{X}$ be a finite dimensional inner-product space, let $\mathfrak{H}=\textrm{Hom}_{\mathbb{R}}(\mathfrak{X},\mathfrak{y})$ and let $\mathfrak{D}$ be the set of all finite $\Delta\subset \mathfrak{X}\times \mathfrak{y}$ such that $\{x \in \Delta\}$ spans $\mathfrak{X}$. Then $\mathfrak{H}$ is surely finite dimensional and each $\Delta$ surely separates $\mathfrak{H}$ (since any linear map is completely defined on a spanning set).<br><br>

The conditions of the above theorem are thus satisfied and we have thus constructed a linear learner. We will call these types of linear learners <b> Euclidean </b> (as $\mathfrak{X}$ is itself a Euclidean space) 
</div>

        </div>
        <footer class="article-footer">
    <a data-url="https://mathvsmachine.com/2018/11/20/introducing-linear-regression..a-little-differently/" data-id="d62c41fd3c5998dbbe09f0903743da80" class="article-share-link">
        <i class="fa fa-share"></i>
        Share
    </a>
    
    <a href="https://mathvsmachine.com/2018/11/20/introducing-linear-regression..a-little-differently/#disqus_thread" class="article-comment-link">
        Comments
    </a>
    

    <script>
    (function ($) {
        
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
    </script>
</footer>

    </div>

    
<nav id="article-nav">
    

    
    <a href="https://mathvsmachine.com/2018/12/01/proving-linear-regression/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">
          Newer
      </strong>
      <div class="article-nav-title">Proving Linear Regression</div>
    </a>
    
</nav>


</article>


<section id="comments">
    <div id="disqus_thread">
        <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "louis-de-thanhoffer" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
</section>


    </section>

   	
    	<aside id="sidebar">
    



<div class="widget-wrap">
    <h3 class="widget-title">
        Recents
    </h3>
    <div class="widget">
        <ul id="recent-post">
            
            <li>
                <div class="item-thumbnail">
                    <a href="https://mathvsmachine.com/2019/03/04/roundup/" class="thumbnail">
                    
                        <span style="background-image:url(https://mathvsmachine.com/thumbnails/linear_regression.png)" alt="Introducing linear regression..a little differently" class="thumbnail-image"></span>
                    
                    </a>
                </div>
                <div class="item-inner">
                    
                    
                    <p class="item-title"><a href="https://mathvsmachine.com/2019/03/04/roundup/" class="title">Roundup</a></p>
                    <p class="item-date">
                        <time datetime="2019-03-04 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2019-03-04</time>
                    </p>
                </div>
            </li>
            
            <li>
                <div class="item-thumbnail">
                    <a href="https://mathvsmachine.com/2019/02/03/coordinates-regression-the-way-we-know-it/" class="thumbnail">
                    
                        <span style="background-image:url(https://mathvsmachine.com/thumbnails/linear_regression.png)" alt="Introducing linear regression..a little differently" class="thumbnail-image"></span>
                    
                    </a>
                </div>
                <div class="item-inner">
                    
                    
                    <p class="item-title"><a href="https://mathvsmachine.com/2019/02/03/coordinates-regression-the-way-we-know-it/" class="title">Coordinates: Regression the way we know it</a></p>
                    <p class="item-date">
                        <time datetime="2019-02-03 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2019-02-03</time>
                    </p>
                </div>
            </li>
            
            <li>
                <div class="item-thumbnail">
                    <a href="https://mathvsmachine.com/2019/01/20/defining-supervised-learning/" class="thumbnail">
                    
                        <span style="background-image:url(https://mathvsmachine.com/thumbnails/supervised_learning.png)" alt="Introducing linear regression..a little differently" class="thumbnail-image"></span>
                    
                    </a>
                </div>
                <div class="item-inner">
                    
                    
                    <p class="item-title"><a href="https://mathvsmachine.com/2019/01/20/defining-supervised-learning/" class="title">Defining Supervised Learning</a></p>
                    <p class="item-date">
                        <time datetime="2019-01-20 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2019-01-20</time>
                    </p>
                </div>
            </li>
            
            <li>
                <div class="item-thumbnail">
                    <a href="https://mathvsmachine.com/2019/01/15/disecting-pseudo-inverses/" class="thumbnail">
                    
                        <span style="background-image:url(https://mathvsmachine.com/thumbnails/linear_regression.png)" alt="Introducing linear regression..a little differently" class="thumbnail-image"></span>
                    
                    </a>
                </div>
                <div class="item-inner">
                    
                    
                    <p class="item-title"><a href="https://mathvsmachine.com/2019/01/15/disecting-pseudo-inverses/" class="title">Disecting Pseudo-inverses</a></p>
                    <p class="item-date">
                        <time datetime="2019-01-15 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2019-01-15</time>
                    </p>
                </div>
            </li>
            
            <li>
                <div class="item-thumbnail">
                    <a href="https://mathvsmachine.com/2018/12/01/proving-linear-regression/" class="thumbnail">
                    
                        <span style="background-image:url(https://mathvsmachine.com/thumbnails/linear_algebra.png)" alt="Introducing linear regression..a little differently" class="thumbnail-image"></span>
                    
                    </a>
                </div>
                <div class="item-inner">
                    
                    
                    <p class="item-title"><a href="https://mathvsmachine.com/2018/12/01/proving-linear-regression/" class="title">Proving Linear Regression</a></p>
                    <p class="item-date">
                        <time datetime="2018-12-01 11:58:06 &#43;0200 &#43;0200" itemprop="datePublished">2018-12-01</time>
                    </p>
                </div>
            </li>
            
        </ul>
    </div>
</div>


    



    



    





<div class="widget-wrap">
    <h3 class="widget-title">
        Tag cloud
    </h3>
    <div class="widget tagcloud">
        
        
        <a href="https://mathvsmachine.com/tags/linear-algebra" style="font-size: 12px;">linear-algebra</a>
        
        
        <a href="https://mathvsmachine.com/tags/linear-regression" style="font-size: 12px;">linear-regression</a>
        
        
        <a href="https://mathvsmachine.com/tags/supervised-learning" style="font-size: 12px;">supervised-learning</a>
        
    </div>
</div>




    




<div class="widget-wrap">
    <h3 class="widget-title"></h3>
    <div class="widget">
        <ul class="category-list">
            
            <li class="category-list-item">
                
                <a class="category-list-link" href="https://mathvsmachine.com/series/linear-regression">
                    linear-regression
                </a>
                <span class="category-list-count">5</span>
            </li>
            
            <li class="category-list-item">
                
                <a class="category-list-link" href="https://mathvsmachine.com/series/supervised-learning">
                    supervised-learning
                </a>
                <span class="category-list-count">1</span>
            </li>
            
        </ul>
    </div>
</div>





    <div id="toTop" class="fa fa-angle-up"></div>
</aside>

    
	


<footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019
      Powered by <a href="//gohugo.io">Hugo</a>.
    </div>
  </div>
</footer>


<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-120720172-1', 'auto');
ga('send', 'pageview');
</script>

<script src="https://mathvsmachine.com/fancybox/jquery.fancybox.pack.js"></script>
<script src="https://mathvsmachine.com/js/script.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>


<script src="https://sonoisa.github.io/xyjax_ext/xypic.js"></script>

<script>hljs.initHighlightingOnLoad();</script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>




</body>
</html>